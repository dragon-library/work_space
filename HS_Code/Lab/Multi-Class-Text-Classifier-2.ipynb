{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A Production ready Multi-Class Text Classifier\n",
    "==\n",
    "\n",
    "- [Reference :](https://towardsdatascience.com/a-production-ready-multi-class-text-classifier-96490408757)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-15T18:30:01.154085Z",
     "start_time": "2020-11-15T18:29:59.008616Z"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline\n",
    "\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from time import time\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "\n",
    "#urls = 'https://github.com/dragon-library/work_space/raw/main/HS_Code/HS/hs_code.xlsx'\n",
    "urls = 'data/hs_code.xlsx'\n",
    "types = 'section'\n",
    "#types = \"chapter\"\n",
    "\n",
    "def get_master(sheets,types = 'section'):\n",
    "    data = pd.read_excel(urls,sheet_name= sheets)\n",
    "    data[types] = data[types].map('{:02}'.format)\n",
    "    data = data[[types,'description']]\n",
    "    data['description'] = data['description'].str.lower()\n",
    " #   data = data.rename(columns={'heading' : 'target', 'product_desc' : 'question_text'})\n",
    "     \n",
    "\n",
    "    return data\n",
    "\n",
    "def manage_data(df):\n",
    "    df.columns =  ['target', 'data'] \n",
    "    \n",
    "    \n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-15T18:31:57.385231Z",
     "start_time": "2020-11-15T18:30:02.366851Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load the dataset: Section\n",
      "Load dataset time:  114.987s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01</td>\n",
       "      <td>horses; live, purebred breeding animals - pure...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01</td>\n",
       "      <td>horses; live, other than purebred breeding ani...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01</td>\n",
       "      <td>asses; live - other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01</td>\n",
       "      <td>mules and hinnies; live-  other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01</td>\n",
       "      <td>cattle; live, purebred breeding animals - pure...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  target                                               data\n",
       "0     01  horses; live, purebred breeding animals - pure...\n",
       "1     01  horses; live, other than purebred breeding ani...\n",
       "2     01                                asses; live - other\n",
       "3     01                    mules and hinnies; live-  other\n",
       "4     01  cattle; live, purebred breeding animals - pure..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "types = \"section\"\n",
    "#types = \"chapter\"\n",
    "\n",
    "print(\"Load the dataset: Section\")\n",
    "t0 = time()\n",
    "\n",
    "sheets = '8_digit'\n",
    "eights = get_master(sheets,types)\n",
    "sheets = '6_digit'\n",
    "sixs = get_master(sheets,types)\n",
    "sheets = '4_digit'\n",
    "fours = get_master(sheets,types)\n",
    "sheets = '2_digit'\n",
    "twos = get_master(sheets,types)\n",
    "\n",
    "sheets = 'test_01'\n",
    "tests = get_master(sheets,types)\n",
    "\n",
    "sheets = 'Declaration_2019_10'\n",
    "decl = get_master(sheets,types)\n",
    "\n",
    "data = pd.concat([eights,sixs,fours,twos,tests,decl], ignore_index=True)\n",
    "df = manage_data(data)\n",
    "\n",
    "\n",
    "#twenty_test = manage_data(tests)\n",
    "load_time = time() - t0\n",
    "print(\"Load dataset time:  %0.3fs\" % load_time)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-15T18:32:11.530436Z",
     "start_time": "2020-11-15T18:32:11.519437Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49137"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-15T18:32:20.313315Z",
     "start_time": "2020-11-15T18:32:20.298316Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>49117</th>\n",
       "      <td>15</td>\n",
       "      <td>aluminium extrusion bar ycbt604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49118</th>\n",
       "      <td>15</td>\n",
       "      <td>aluminium fitting txjbr625173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49119</th>\n",
       "      <td>15</td>\n",
       "      <td>aluminium window frame kb157112asaa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49120</th>\n",
       "      <td>16</td>\n",
       "      <td>automotive batteries wet charged model  75d23r</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49121</th>\n",
       "      <td>16</td>\n",
       "      <td>a/s jdmkey fpcb_volume key_a107f_svcsm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49122</th>\n",
       "      <td>17</td>\n",
       "      <td>assy tire 11.224 rot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49123</th>\n",
       "      <td>15</td>\n",
       "      <td>aluminium extrusion bar ycrk601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49124</th>\n",
       "      <td>16</td>\n",
       "      <td>assy elementfuel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49125</th>\n",
       "      <td>15</td>\n",
       "      <td>aluminium window frame t02609abbb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49126</th>\n",
       "      <td>15</td>\n",
       "      <td>aluminium ornament for door cc0010dnje</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49127</th>\n",
       "      <td>15</td>\n",
       "      <td>aluminium window frame aaabaabz165132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49128</th>\n",
       "      <td>15</td>\n",
       "      <td>aluminium window frame w02609abbb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49129</th>\n",
       "      <td>15</td>\n",
       "      <td>aluminium ornament for door kh111peac</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49130</th>\n",
       "      <td>15</td>\n",
       "      <td>aluminium window frame tf116112asaa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49131</th>\n",
       "      <td>16</td>\n",
       "      <td>assy lp kit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49132</th>\n",
       "      <td>15</td>\n",
       "      <td>adjust gear set jfkz658b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49133</th>\n",
       "      <td>15</td>\n",
       "      <td>aluminium window frame kf057072avat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49134</th>\n",
       "      <td>07</td>\n",
       "      <td>acrylic plate 4mm. size24x24 cm.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49135</th>\n",
       "      <td>16</td>\n",
       "      <td>ac power cord p/n 141102240p6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49136</th>\n",
       "      <td>17</td>\n",
       "      <td>automotive disc brake pads 220177988 db24114wd</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      target                                            data\n",
       "49117     15                 aluminium extrusion bar ycbt604\n",
       "49118     15                   aluminium fitting txjbr625173\n",
       "49119     15             aluminium window frame kb157112asaa\n",
       "49120     16  automotive batteries wet charged model  75d23r\n",
       "49121     16          a/s jdmkey fpcb_volume key_a107f_svcsm\n",
       "49122     17                            assy tire 11.224 rot\n",
       "49123     15                 aluminium extrusion bar ycrk601\n",
       "49124     16                                assy elementfuel\n",
       "49125     15               aluminium window frame t02609abbb\n",
       "49126     15          aluminium ornament for door cc0010dnje\n",
       "49127     15           aluminium window frame aaabaabz165132\n",
       "49128     15               aluminium window frame w02609abbb\n",
       "49129     15           aluminium ornament for door kh111peac\n",
       "49130     15             aluminium window frame tf116112asaa\n",
       "49131     16                                     assy lp kit\n",
       "49132     15                        adjust gear set jfkz658b\n",
       "49133     15             aluminium window frame kf057072avat\n",
       "49134     07                acrylic plate 4mm. size24x24 cm.\n",
       "49135     16                   ac power cord p/n 141102240p6\n",
       "49136     17  automotive disc brake pads 220177988 db24114wd"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-15T18:32:40.474360Z",
     "start_time": "2020-11-15T18:32:40.268326Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save DataFrame\n",
      "success\n"
     ]
    }
   ],
   "source": [
    "#save the DataFrame\n",
    "print(\"Save DataFrame\")\n",
    "import joblib\n",
    "joblib.dump(df, 'train_section.pkl', compress=1)\n",
    "print('success')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load DataFrame\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01</td>\n",
       "      <td>horses; live, purebred breeding animals - pure...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01</td>\n",
       "      <td>horses; live, other than purebred breeding ani...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01</td>\n",
       "      <td>asses; live - other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01</td>\n",
       "      <td>mules and hinnies; live-  other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01</td>\n",
       "      <td>cattle; live, purebred breeding animals - pure...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  target                                               data\n",
       "0     01  horses; live, purebred breeding animals - pure...\n",
       "1     01  horses; live, other than purebred breeding ani...\n",
       "2     01                                asses; live - other\n",
       "3     01                    mules and hinnies; live-  other\n",
       "4     01  cattle; live, purebred breeding animals - pure..."
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "print(\"Load DataFrame\")\n",
    "df = joblib.load('train_section.pkl')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-16T19:08:36.875112Z",
     "start_time": "2020-11-16T19:08:36.647116Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Path' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-f5b1e71985fc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdata_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'..'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'data'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mdata_path\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mdata_path\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmkdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparents\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mparquet_file\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata_path\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;34m'train.parquet'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Path' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "data_path = Path('..', 'data')\n",
    "if not data_path.exists():\n",
    "    data_path.mkdir(parents=True)\n",
    "\n",
    "parquet_file = data_path / 'train.parquet'\n",
    "\n",
    "df.to_parquet(parquet_file)\n",
    "print('success')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "twenty_train = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'01': 126,\n",
       "         '02': 253,\n",
       "         '03': 907,\n",
       "         '04': 365,\n",
       "         '05': 70,\n",
       "         '06': 89,\n",
       "         '07': 391,\n",
       "         '08': 310,\n",
       "         '09': 172,\n",
       "         '10': 106,\n",
       "         '11': 117,\n",
       "         '12': 217,\n",
       "         '13': 52,\n",
       "         '14': 33,\n",
       "         '15': 327,\n",
       "         '16': 265,\n",
       "         '17': 141,\n",
       "         '18': 133,\n",
       "         '19': 204,\n",
       "         '20': 432,\n",
       "         '21': 259,\n",
       "         '22': 402,\n",
       "         '23': 247,\n",
       "         '24': 125,\n",
       "         '25': 268,\n",
       "         '26': 156,\n",
       "         '27': 267,\n",
       "         '28': 751,\n",
       "         '29': 1940,\n",
       "         '30': 297,\n",
       "         '31': 90,\n",
       "         '32': 338,\n",
       "         '33': 477,\n",
       "         '34': 257,\n",
       "         '35': 117,\n",
       "         '36': 49,\n",
       "         '37': 198,\n",
       "         '38': 531,\n",
       "         '39': 1710,\n",
       "         '40': 1158,\n",
       "         '41': 225,\n",
       "         '42': 204,\n",
       "         '43': 54,\n",
       "         '44': 602,\n",
       "         '45': 38,\n",
       "         '46': 105,\n",
       "         '47': 71,\n",
       "         '48': 682,\n",
       "         '49': 148,\n",
       "         '50': 45,\n",
       "         '51': 193,\n",
       "         '52': 516,\n",
       "         '53': 96,\n",
       "         '54': 314,\n",
       "         '55': 384,\n",
       "         '56': 152,\n",
       "         '57': 153,\n",
       "         '58': 212,\n",
       "         '59': 145,\n",
       "         '60': 196,\n",
       "         '61': 558,\n",
       "         '62': 797,\n",
       "         '63': 287,\n",
       "         '64': 247,\n",
       "         '65': 63,\n",
       "         '66': 25,\n",
       "         '67': 59,\n",
       "         '68': 265,\n",
       "         '69': 259,\n",
       "         '70': 468,\n",
       "         '71': 590,\n",
       "         '72': 848,\n",
       "         '73': 1484,\n",
       "         '74': 253,\n",
       "         '75': 73,\n",
       "         '76': 6585,\n",
       "         '78': 47,\n",
       "         '79': 47,\n",
       "         '80': 39,\n",
       "         '81': 183,\n",
       "         '82': 403,\n",
       "         '83': 444,\n",
       "         '84': 4505,\n",
       "         '85': 3947,\n",
       "         '86': 141,\n",
       "         '87': 4593,\n",
       "         '88': 294,\n",
       "         '89': 106,\n",
       "         '90': 1040,\n",
       "         '91': 320,\n",
       "         '92': 110,\n",
       "         '93': 89,\n",
       "         '94': 473,\n",
       "         '95': 222,\n",
       "         '96': 358,\n",
       "         '97': 33})"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "Counter(twenty_train[\"target\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re \n",
    "def clean_str(string):\n",
    "    \"\"\"\n",
    "    Tokenization/string cleaning for dataset\n",
    "    Every dataset is lower cased except\n",
    "    \"\"\"\n",
    "    string = re.sub(r\"\\n\", \"\", string)    \n",
    "    string = re.sub(r\"\\r\", \"\", string) \n",
    "    string = re.sub(r\"[0-9]\", \"digit\", string)\n",
    "    string = re.sub(r\"\\'\", \"\", string)    \n",
    "    string = re.sub(r\"\\\"\", \"\", string)    \n",
    "    return string.strip().lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train test split dataset\n"
     ]
    }
   ],
   "source": [
    "print(\"train test split dataset\")\n",
    "#train test split\n",
    "df = twenty_train.copy()\n",
    "from sklearn.model_selection import train_test_split\n",
    "X = []\n",
    "for i in range(df.shape[0]):\n",
    "    X.append(clean_str(df.iloc[i][1]))\n",
    "y = np.array(df[\"target\"])\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['womens or girls slips and petticoats, not knitted or crocheted, of cotton',\n",
       " 'woven cotton fabric, digitdigit% or more cotton by weight, plain weave, over digitdigitdigit but n/o digitdigitdigit g/mdigit, bleached, of number digitdigit or lower',\n",
       " 'regulating or controlling instruments and apparatus; automatic, parts and accessories - of goods of subheading digitdigitdigitdigit.digitdigit.digitdigit',\n",
       " 'absorber asm rr shk',\n",
       " 'fish; edible offal, other than shark fins, fish heads, tails and maws',\n",
       " 'automotive disc brake pads digitdigitdigitdigitdigitdigitdigitdigitdigit set tdbdigitdigitdigitdigit metab',\n",
       " 'aluminium fabrication bar ejhagzdigitdigitdigitdigit',\n",
       " 'stationery; letter clips, letter corners, paper clips, indexing tags and similar office articles, including parts, of base metal - other',\n",
       " 'adigitdigitdigitdigitdigitdigitdigitdigit floor nozzle led lights',\n",
       " 'aquatic plants',\n",
       " 'accustar life bnkdigitdigitdigitdigitdigitdigitdigitdigitdigit digitdigitdigitdigitdigitdigitdigitdigit',\n",
       " 'fabrics, woven; of carded wool or carded fine animal hair, containing less than digitdigit% by weight of wool or fine animal hair, mixed mainly or solely with man-made staple fibres',\n",
       " 'albin alarm clock digitdigitxdigit.digitxdigitdigit.digitcm wt',\n",
       " 'air conditioner parts insulation comp. part no. rctdigitdigitdigitddigitdigitdigitc',\n",
       " 'axle assy rr',\n",
       " 'watermelons, fresh, if entered during the period from december digit, in any year, to the following march digitdigit, inclusive',\n",
       " 'auto parts     air brake booster  digitdigitdigitdigitdigitdigitdigitdigit',\n",
       " 'woven fabrics of polyester staple fibers, < digitdigit% by wt polyester staple fibers, mixed mainly/solely w/cotton, not over digitdigitdigit g/mdigit, dyed, nesoi',\n",
       " 'alcohols; polyhydric, digitethyldigit (hydroxymethyl) propanedigit,digitdiol (trimethylolpropane) - \\xa0digitethyldigit(hydroxymethyl)propanedigit,digitdiol (trimethylolpropane)',\n",
       " 'harvesting machinery; for roots or tubers',\n",
       " 'birch wood in the rough/roughly squared, greater than or equal to digitdigit cm, not treated with preservatives',\n",
       " 'womens or girls slips and petticoats, of textile materials (except mmf or cotton), cont under digitdigit% by weight of silk or silk waste, not k/c',\n",
       " 'valves and tubes; parts of the valves and tubes of heading no. digitdigitdigitdigit, excluding parts of cathoderay tubes - other',\n",
       " 'aeroflex rubber insulation tube aeroflex tube dia.digitdigitmmxdigitdigitmmxdigitm.',\n",
       " 'residual products of the chemical or allied industries, not elsewhere specified or included; clinical waste - syringes, needles, cannulae and the like',\n",
       " 'mens or boys suit-type jackets and blazers, of text materials(except wool, cotton or mmf), containing under digitdigit% by weight of silk, not k/c',\n",
       " 'single textured polypropylene yarn, not put up for retail sale',\n",
       " 'waterproof footwear, not mechanically asmbld, w/outer soles and uppers of rubber or plastics, nesoi, not cover ankle',\n",
       " 'aluminium fabrication bar kdigitdigittgfa',\n",
       " 'other monophenols',\n",
       " 'plants and parts (including seeds and fruits) n.e.c. in heading no. digitdigitdigitdigit, of a kind used primarily in perfumery, in pharmacy or for insecticidal, fungicidal or similar purposes, fresh, chilled, frozen or dried, whether or not cut, crushed or powdered -',\n",
       " 'panty hose (not graduated compressoin) and tights, containing digitdigit% or more by weight of silk or silk waste, knitted or crocheted',\n",
       " 'apdigitdigitdigitdigitdigitdigit prem. active carbon digitlt',\n",
       " 'other perbromates, iodates and periodates other than potassium',\n",
       " 'ethylene polymers; waste, parings and scrap - other',\n",
       " 'woven silk fabrics, containing digitdigit percent or more by weight of silk or silk waste, nesoi',\n",
       " 'prepared or preserved pork, not containing cereals or vegetables, nesoi',\n",
       " 'taps, cocks, valves and similar appliances; parts thereof - other',\n",
       " 'alpha gold @digitxdigitl',\n",
       " 'flour, meal, powder, flakes, granules and pellets of potatoes',\n",
       " 'ensembles; womens or girls, of cotton (not knitted or crocheted) - other',\n",
       " 'mens or boys anoraks, windbreakers and similar articles nesoi, not knitted or crocheted, of wool or fine animal hair, o/than rec perf outwear',\n",
       " 'iron or nonalloy steel; in coils, without patterns in relief, flatrolled, of a width digitdigitdigitmm or more, hotrolled, pickled, of a thickness of digitmm or more but less than digit.digitdigitmm - of a thickness of digit mm or more but less than digit.digitdigit mm',\n",
       " 'machines and appliances; for testing the hardness, strength, compressibility, elasticity or other mechanical properties of metals',\n",
       " 'fabrics, woven; of carded wool or of carded fine animal hair, containing digitdigit% or more by weight of wool or of fine animal hair, of a weight not exceeding digitdigitdigitg/mdigit - \\xa0of a weight not exceeding digitdigitdigit g/mdigit',\n",
       " 'apkdigitdigitfhdigitdigitdigitdigitdigitza sticker wheel digitdigit red',\n",
       " 'automobile parts digitdigitdigitdigitdigitrlvadigitdigitdigitb cap assyreserve',\n",
       " 'aluminium window frame tmdigitdigitdigitdigitdigitlargs',\n",
       " 'purified egg phospholipids, pharmaceutical grade meeting requirements of the u.s. fda for use in intravenous fat emulsion',\n",
       " 'crustaceans; frozen, shrimps and prawns, excluding coldwater varieties, in shell or not, smoked, cooked or not before or during smoking; in shell, cooked by steaming or by boiling in water -  headless, with tail',\n",
       " 'nickel chloride',\n",
       " 'ab  control box metal b',\n",
       " 'benzaldehyde',\n",
       " 'aluminium window frame tfdigitdigitdigitdigitdigitdigitaval',\n",
       " 'arb rear bar jk jeep',\n",
       " 'alum.roasted pan w/stove digitdigit cm',\n",
       " 'salts of triethanolamine',\n",
       " 'multiple or cabled cotton yarn, digitdigit% or more cotton by weight, of uncombed fibers, n/o digitdigit nm per single yarn, not put up for retail sale',\n",
       " 'aromatic monoamines and their derivatives and salts thereof, nesoi',\n",
       " 'abdigitdigit digitdigitdigitdigitdigitdigitdigit aa plt dr o/s nm',\n",
       " 'electro-medical instruments and appliances nesoi, and parts and accessories thereof',\n",
       " 'adigitdigitdigitdigitdigitdigitdigitdigit   motor fan shaded pole cu wd',\n",
       " 'titanium ores and concentrates - ilmenite ores and concentrates',\n",
       " 'ice cream and other edible ice; whether or not containing cocoa',\n",
       " 'chlorides; of aluminium',\n",
       " 'mirrors, unmounted',\n",
       " 'homogenized vegetables, prepared or preserved otherwise than by vinegar or acetic acid, not frozen',\n",
       " 'calcium nitrate',\n",
       " 'automotive batteries leadacid digitdigiteadigitdigitdigitl smf',\n",
       " 'assy cleanerair',\n",
       " 'tobacco; smoking, water pipe tobacco as specified in subheading note digit to this chapter, whether or not containing tobacco substitutes in any proportion',\n",
       " 'aquatic invertebrates; sea cucumbers (stichopus japonicus, holothuroidea), dried, salted or in brine, smoked, whether or not cooked before or during the smoking process',\n",
       " 'dyed warp knit fabrics (including those made on galloon knitting machines) of artificial fibers, other than those of headings digitdigitdigitdigit to digitdigitdigitdigit',\n",
       " 'hexamethylenetetramine',\n",
       " 'office machines; not elsewhere classified - automatic',\n",
       " 'wood, tropical; dark red meranti, light red meranti and meranti bakau, sawn or chipped lengthwise, sliced or peeled, whether or not planed, sanded or endjointed, thicker than digitmm -  other',\n",
       " 'base metals or silver, clad with gold, not further worked than semi-manufactured',\n",
       " 'fish fillets; frozen, toothfish (dissostichus spp.)',\n",
       " 'aircraft n.e.c. in heading no. digitdigitdigitdigit (e.g. helicopters, aeroplanes); spacecraft (including satellites) and suborbital and spacecraft launch vehicles',\n",
       " 'abdigitdigit digitdigitdigitdigitdigitdigitdigitbbsmsr handle dr lh',\n",
       " 'assy roof standard  digitdigitdigit x digitdigitdigitdigitmm',\n",
       " 'ceramic (o/than porcelain or china) household articles and toilet articles (o/than table and kitchenware), nesoi',\n",
       " 'plastics; plates, sheets, film, foil and strip (not selfadhesive), of poly(ethylene terephthalate), noncellular and not reinforced, laminated, supported or similarly combined with other materials - other',\n",
       " 'dextrins and other modified starches - other',\n",
       " 'octopus, dried, salted or in brine',\n",
       " 'airnails fdigitdigit eurox',\n",
       " 'parts of railway/tramway locomotives/rolling stock, pts of brakes (o/th air brakes) for self-propelled vehicles or non-self-propelled nesoi',\n",
       " 'aircraft parts',\n",
       " 'abdigitdigit digitdigitdigitdigitdigitdigitdigit aa pnl frt rf otr',\n",
       " 'amino-naphthols and other amino-phenols, other than those containing more than one kind of oxygen function, their ethers and esters; salts thereof n.e.c. in item no. digitdigitdigitdigit.digit',\n",
       " 'vitamins; vitamin c and its derivatives, unmixed',\n",
       " 'butter subject to general note digitdigit (outside quota)',\n",
       " 'ambinyl orange digitg digitdigitdigit% new grains',\n",
       " 'buffalo hides and skins nesoi, w/o hair on, unit surface area ov digit.digit mdigit, tanned but not further prepared, in the wet state',\n",
       " 'auydigitdigit cabinet c',\n",
       " 'aluminium ornament for door wadigitdigitdigitpeac',\n",
       " 'alloy wheels y digitdigitdigitdigit digith/digitdigitdigit.digit etdigitdigit cbdigitdigit.digit titan matt  iddigitdigitdigitdigitdigitdigit',\n",
       " 'alb. algae eater',\n",
       " 'aluminium window frame kkdigitdigitdigitdigitdigitarjx',\n",
       " 'other basic paper be sensitized use in photography, wt. digitdigitg/mdigit-digitdigitdigitg/mdigit, n/o digitdigit% total fiber by mechanical/chemi- process, other sized sheets',\n",
       " 'grapefruit juice, brix value not exceeding digitdigit, not concentrated and not made from a juice degree of concentration of digit.digit or >, unfermented',\n",
       " 'arsenic',\n",
       " 'chassis; fitted with engines, for the motor vehicles of heading no. digitdigitdigitdigit to digitdigitdigitdigit - other',\n",
       " 'spinach, new zealand spinach and orache spinach (garden spinach), uncooked or cooked by steaming or boiling in water, frozen',\n",
       " 'aro toilet cleaner',\n",
       " 'press-fasteners, snap-fasteners and press-studs and pts thereof, valued n/o digitdigit cents/dozen pieces or parts',\n",
       " 'railway or tramway coaches, vans "
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<b>limit_output extension: Maximum message size of 10000 exceeded with 98065 characters</b>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['28', '73', '87', ..., '29', '16', '39'], dtype=object)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: \n"
     ]
    }
   ],
   "source": [
    "#feature engineering and model selection\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "print(\"Training: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pipeline of feature engineering and model\n",
    "t0 = time()\n",
    "model = Pipeline([('vectorizer', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', OneVsRestClassifier(LinearSVC(class_weight=\"balanced\")))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "paramater selection\n"
     ]
    }
   ],
   "source": [
    "print(\"paramater selection\")\n",
    "#paramater selection\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "parameters = {'vectorizer__ngram_range': [(1, 1), (1, 2),(2,2)],\n",
    "               'tfidf__use_idf': (True, False)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8787852808408421\n",
      "{'tfidf__use_idf': True, 'vectorizer__ngram_range': (1, 2)}\n"
     ]
    }
   ],
   "source": [
    "gs_clf_svm = GridSearchCV(model, parameters, n_jobs=-1)\n",
    "gs_clf_svm = gs_clf_svm.fit(X, y)\n",
    "print(gs_clf_svm.best_score_)\n",
    "print(gs_clf_svm.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preparing the final pipeline using the selected parameters\n"
     ]
    }
   ],
   "source": [
    "#preparing the final pipeline using the selected parameters\n",
    "print(\"preparing the final pipeline using the selected parameters\")\n",
    "model = Pipeline([('vectorizer', CountVectorizer(ngram_range=(1,2))),\n",
    "    ('tfidf', TfidfTransformer(use_idf=True)),\n",
    "    ('clf', OneVsRestClassifier(LinearSVC(class_weight=\"balanced\")))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model with training data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train time: 1009.945s\n"
     ]
    }
   ],
   "source": [
    "#fit model with training data\n",
    "print(\"fit model with training data\")\n",
    "model.fit(X_train, y_train)\n",
    "train_time = time() - t0\n",
    "print(\"train time: %0.3fs\" % train_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test time:  1.653s\n"
     ]
    }
   ],
   "source": [
    "#evaluation on test data\n",
    "t0 = time()\n",
    "pred = model.predict(X_test)\n",
    "test_time = time() - t0\n",
    "print(\"test time:  %0.3fs\" % test_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['01', '02', '03', '04', '05', '06', '07', '08', '09', '10', '11',\n",
       "       '12', '13', '14', '15', '16', '17', '18', '19', '20', '21'],\n",
       "      dtype='<U2')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 519,    0,    0,    1,    0,    3,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
       "       [   0,  463,    0,    5,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    1,    0,    0,    0],\n",
       "       [   0,    0,   93,    0,    0,    2,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
       "       [   0,    0,    0,  593,    0,   11,    3,    0,    1,    1,    1,\n",
       "           0,    0,    1,    6,    2,    1,    3,    0,    2,    0],\n",
       "       [   0,    0,    0,    1,  195,    3,    1,    0,    0,    0,    0,\n",
       "           0,    1,    0,    1,    0,    1,    0,    0,    1,    0],\n",
       "       [   1,    1,    1,   15,    6, 1469,    9,    0,    0,    3,    3,\n",
       "           1,    0,    2,    4,   16,    3,    3,    0,    4,    0],\n",
       "       [   0,    0,    0,    2,    0,    6,  689,    1,    0,    0,    3,\n",
       "           0,    2,    1,    8,   21,   43,    4,    0,    8,    0],\n",
       "       [   0,    0,    0,    0,    0,    2,    0,  140,    0,    0,    1,\n",
       "           1,    0,    0,    3,    1,    0,    0,    0,    3,    0],\n",
       "       [   0,    0,    0,    1,    0,    0,    0,    0,  219,    2,    2,\n",
       "           0,    0,    0,    1,    2,    0,    0,    0,    1,    0],\n",
       "       [   0,    0,    0,    1,    0,    2,    1,    1,    0,  262,    0,\n",
       "           0,    0,    0,    1,    3,    1,    0,    0,    0,    0],\n",
       "       [   0,    0,    0,    0,    0,    0,    1,    1,    1,    2, 1210,\n",
       "           6,    0,    0,    0,    1,    2,    0,    0,    3,    0],\n",
       "       [   2,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "         124,    0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
       "       [   0,    0,    0,    0,    1,    1,    4,    0,    1,    1,    1,\n",
       "           1,  276,    1,    3,    7,    6,    0,    0,    0,    0],\n",
       "       [   0,    0,    0,    0,    0,    0,    2,    2,    0,    0,    2,\n",
       "           0,    1,  164,    2,    3,    1,    1,    0,    6,    0],\n",
       "       [   0,    0,    0,    1,    1,   10,   11,    0,    0,    1,    3,\n",
       "           1,    1,    6, 2963,   28,   32,    6,    0,    2,    0],\n",
       "       [   0,    3,    0,    4,    0,   43,   64,    0,    1,    5,    6,\n",
       "           0,    1,    9,   55, 2348,   67,   46,    1,   10,    0],\n",
       "       [   1,    0,    0,    0,    1,    7,   55,    1,    1,    1,    3,\n",
       "           1,    6,    0,   67,   74, 1316,    6,    0,    1,    0],\n",
       "       [   0,    0,    0,    0,    0,    0,    5,    1,    0,    1,    0,\n",
       "           0,    2,    0,    1,   15,    5,  370,    0,    0,    0],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,   21,    0,    0],\n",
       "       [   0,    0,    0,    0,    0,    0,    4,    1,    0,    0,    2,\n",
       "           0,    1,    1,    6,    3,    3,    0,    1,  282,    0],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    1,    0,    0,    0,    0,   10]],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "confusion_matrix(pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9310812644145977"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          01       0.99      0.99      0.99       523\n",
      "          02       0.99      0.99      0.99       467\n",
      "          03       0.98      0.99      0.98        94\n",
      "          04       0.95      0.95      0.95       624\n",
      "          05       0.96      0.96      0.96       204\n",
      "          06       0.95      0.94      0.95      1559\n",
      "          07       0.87      0.81      0.84       849\n",
      "          08       0.93      0.95      0.94       148\n",
      "          09       0.96      0.98      0.97       224\n",
      "          10       0.96      0.94      0.95       279\n",
      "          11       0.99      0.98      0.98      1237\n",
      "          12       0.98      0.92      0.95       135\n",
      "          13       0.91      0.95      0.93       291\n",
      "          14       0.89      0.89      0.89       185\n",
      "          15       0.97      0.95      0.96      3121\n",
      "          16       0.88      0.93      0.91      2525\n",
      "          17       0.85      0.89      0.87      1481\n",
      "          18       0.93      0.84      0.88       440\n",
      "          19       1.00      0.91      0.95        23\n",
      "          20       0.93      0.87      0.90       323\n",
      "          21       0.91      1.00      0.95        10\n",
      "\n",
      "    accuracy                           0.93     14742\n",
      "   macro avg       0.94      0.93      0.94     14742\n",
      "weighted avg       0.93      0.93      0.93     14742\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print (classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save Model\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['model_section.pkl']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#save the model\n",
    "print(\"Save Model\")\n",
    "import joblib\n",
    "joblib.dump(model, 'model_section.pkl', compress=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load Model\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "print(\"Load Model\")\n",
    "model = joblib.load('model_section.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video game consoles\n"
     ]
    }
   ],
   "source": [
    "products = input()  # Video game consoles : 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'20'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict([products])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chapter Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-15T20:01:29.552781Z",
     "start_time": "2020-11-15T19:59:32.768726Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load the dataset : chapter\n",
      "Load dataset time:  116.764s\n",
      "49137\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01</td>\n",
       "      <td>horses; live, purebred breeding animals - pure...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01</td>\n",
       "      <td>horses; live, other than purebred breeding ani...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01</td>\n",
       "      <td>asses; live - other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01</td>\n",
       "      <td>mules and hinnies; live-  other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01</td>\n",
       "      <td>cattle; live, purebred breeding animals - pure...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  target                                               data\n",
       "0     01  horses; live, purebred breeding animals - pure...\n",
       "1     01  horses; live, other than purebred breeding ani...\n",
       "2     01                                asses; live - other\n",
       "3     01                    mules and hinnies; live-  other\n",
       "4     01  cattle; live, purebred breeding animals - pure..."
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#types = \"section\"\n",
    "types = \"chapter\"\n",
    "\n",
    "print(\"Load the dataset : chapter\")\n",
    "t0 = time()\n",
    "\n",
    "\n",
    "sheets = '8_digit'\n",
    "eights = get_master(sheets,types)\n",
    "sheets = '6_digit'\n",
    "sixs = get_master(sheets,types)\n",
    "sheets = '4_digit'\n",
    "fours = get_master(sheets,types)\n",
    "sheets = '2_digit'\n",
    "twos = get_master(sheets,types)\n",
    "\n",
    "sheets = 'test_01'\n",
    "tests = get_master(sheets,types)\n",
    "\n",
    "sheets = 'Declaration_2019_10'\n",
    "decl = get_master(sheets,types)\n",
    "\n",
    "data = pd.concat([eights,sixs,fours,twos,tests,decl], ignore_index=True)\n",
    "twenty_train = manage_data(data)\n",
    "\n",
    "\n",
    "\n",
    "#twenty_test = manage_data(tests)\n",
    "\n",
    "load_time = time() - t0\n",
    "print(\"Load dataset time:  %0.3fs\" % load_time)\n",
    "print(len(twenty_train))\n",
    "twenty_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-15T20:01:29.630779Z",
     "start_time": "2020-11-15T20:01:29.556783Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'01': 126,\n",
       "         '02': 253,\n",
       "         '03': 907,\n",
       "         '04': 365,\n",
       "         '05': 70,\n",
       "         '06': 89,\n",
       "         '07': 391,\n",
       "         '08': 310,\n",
       "         '09': 172,\n",
       "         '10': 106,\n",
       "         '11': 117,\n",
       "         '12': 217,\n",
       "         '13': 52,\n",
       "         '14': 33,\n",
       "         '15': 327,\n",
       "         '16': 265,\n",
       "         '17': 141,\n",
       "         '18': 133,\n",
       "         '19': 204,\n",
       "         '20': 432,\n",
       "         '21': 259,\n",
       "         '22': 402,\n",
       "         '23': 247,\n",
       "         '24': 125,\n",
       "         '25': 268,\n",
       "         '26': 156,\n",
       "         '27': 267,\n",
       "         '28': 751,\n",
       "         '29': 1940,\n",
       "         '30': 297,\n",
       "         '31': 90,\n",
       "         '32': 338,\n",
       "         '33': 477,\n",
       "         '34': 257,\n",
       "         '35': 117,\n",
       "         '36': 49,\n",
       "         '37': 198,\n",
       "         '38': 531,\n",
       "         '39': 1710,\n",
       "         '40': 1158,\n",
       "         '41': 225,\n",
       "         '42': 204,\n",
       "         '43': 54,\n",
       "         '44': 602,\n",
       "         '45': 38,\n",
       "         '46': 105,\n",
       "         '47': 71,\n",
       "         '48': 682,\n",
       "         '49': 148,\n",
       "         '50': 45,\n",
       "         '51': 193,\n",
       "         '52': 516,\n",
       "         '53': 96,\n",
       "         '54': 314,\n",
       "         '55': 384,\n",
       "         '56': 152,\n",
       "         '57': 153,\n",
       "         '58': 212,\n",
       "         '59': 145,\n",
       "         '60': 196,\n",
       "         '61': 558,\n",
       "         '62': 797,\n",
       "         '63': 287,\n",
       "         '64': 247,\n",
       "         '65': 63,\n",
       "         '66': 25,\n",
       "         '67': 59,\n",
       "         '68': 265,\n",
       "         '69': 259,\n",
       "         '70': 468,\n",
       "         '71': 590,\n",
       "         '72': 848,\n",
       "         '73': 1484,\n",
       "         '74': 253,\n",
       "         '75': 73,\n",
       "         '76': 6585,\n",
       "         '78': 47,\n",
       "         '79': 47,\n",
       "         '80': 39,\n",
       "         '81': 183,\n",
       "         '82': 403,\n",
       "         '83': 444,\n",
       "         '84': 4505,\n",
       "         '85': 3947,\n",
       "         '86': 141,\n",
       "         '87': 4593,\n",
       "         '88': 294,\n",
       "         '89': 106,\n",
       "         '90': 1040,\n",
       "         '91': 320,\n",
       "         '92': 110,\n",
       "         '93': 89,\n",
       "         '94': 473,\n",
       "         '95': 222,\n",
       "         '96': 358,\n",
       "         '97': 33})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "Counter(twenty_train[\"target\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-15T20:02:43.636955Z",
     "start_time": "2020-11-15T20:02:43.428996Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save DataFrame\n",
      "success\n"
     ]
    }
   ],
   "source": [
    "#save the DataFrame\n",
    "print(\"Save DataFrame\")\n",
    "import joblib\n",
    "joblib.dump(twenty_train, 'train_chapter.pkl', compress=1)\n",
    "print('success')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re \n",
    "def clean_str(string):\n",
    "    \"\"\"\n",
    "    Tokenization/string cleaning for dataset\n",
    "    Every dataset is lower cased except\n",
    "    \"\"\"\n",
    "    string = re.sub(r\"\\n\", \"\", string)    \n",
    "    string = re.sub(r\"\\r\", \"\", string) \n",
    "    string = re.sub(r\"[0-9]\", \"digit\", string)\n",
    "    string = re.sub(r\"\\'\", \"\", string)    \n",
    "    string = re.sub(r\"\\\"\", \"\", string)    \n",
    "    return string.strip().lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rain test split\n"
     ]
    }
   ],
   "source": [
    "#train test split\n",
    "print(\"rain test split\")\n",
    "df = twenty_train.copy()\n",
    "from sklearn.model_selection import train_test_split\n",
    "X = []\n",
    "for i in range(df.shape[0]):\n",
    "    X.append(clean_str(df.iloc[i][1]))\n",
    "y = np.array(df[\"target\"])\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature engineering and model selection\n"
     ]
    }
   ],
   "source": [
    "#feature engineering and model selection\n",
    "print(\"feature engineering and model selection\")\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pipeline of feature engineering and model\n"
     ]
    }
   ],
   "source": [
    "#pipeline of feature engineering and model\n",
    "print(\"pipeline of feature engineering and model\")\n",
    "model = Pipeline([('vectorizer', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', OneVsRestClassifier(LinearSVC(class_weight=\"balanced\")))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "paramater selection\n"
     ]
    }
   ],
   "source": [
    "#paramater selection\n",
    "print(\"paramater selection\")\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "parameters = {'vectorizer__ngram_range': [(1, 1), (1, 2),(2,2)],\n",
    "               'tfidf__use_idf': (True, False)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8671036298745671\n",
      "{'tfidf__use_idf': True, 'vectorizer__ngram_range': (1, 2)}\n"
     ]
    }
   ],
   "source": [
    "print(\"Training: \")\n",
    "   \n",
    "t0 = time()\n",
    "gs_clf_svm = GridSearchCV(model, parameters, n_jobs=-1)\n",
    "gs_clf_svm = gs_clf_svm.fit(X, y)\n",
    "print(gs_clf_svm.best_score_)\n",
    "print(gs_clf_svm.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preparing the final pipeline using the selected parameters\n",
    "model = Pipeline([('vectorizer', CountVectorizer(ngram_range=(1,2))),\n",
    "    ('tfidf', TfidfTransformer(use_idf=True)),\n",
    "    ('clf', OneVsRestClassifier(LinearSVC(class_weight=\"balanced\")))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train time: 3068.481s\n"
     ]
    }
   ],
   "source": [
    "#fit model with training data\n",
    "model.fit(X_train, y_train)\n",
    "train_time = time() - t0\n",
    "print(\"train time: %0.3fs\" % train_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test time:  0.684s\n"
     ]
    }
   ],
   "source": [
    "#evaluation on test data\n",
    "t0 = time()\n",
    "pred = model.predict(X_test)\n",
    "\n",
    "test_time = time() - t0\n",
    "print(\"test time:  %0.3fs\" % test_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['01', '02', '03', '04', '05', '06', '07', '08', '09', '10', '11',\n",
       "       '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22',\n",
       "       '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33',\n",
       "       '34', '35', '36', '37', '38', '39', '40', '41', '42', '43', '44',\n",
       "       '45', '46', '47', '48', '49', '50', '51', '52', '53', '54', '55',\n",
       "       '56', '57', '58', '59', '60', '61', '62', '63', '64', '65', '66',\n",
       "       '67', '68', '69', '70', '71', '72', '73', '74', '75', '76', '78',\n",
       "       '79', '80', '81', '82', '83', '84', '85', '86', '87', '88', '89',\n",
       "       '90', '91', '92', '93', '94', '95', '96', '97'], dtype='<U2')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 37,   0,   2, ...,   0,   0,   0],\n",
       "       [  0,  72,   0, ...,   0,   0,   0],\n",
       "       [  0,   0, 280, ...,   0,   0,   0],\n",
       "       ...,\n",
       "       [  0,   0,   0, ...,  49,   0,   0],\n",
       "       [  0,   0,   0, ...,   0, 103,   0],\n",
       "       [  0,   0,   0, ...,   0,   0,  10]], dtype=int64)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "confusion_matrix(pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9134445801112467\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_test, pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          01       0.95      1.00      0.97        37\n",
      "          02       1.00      1.00      1.00        72\n",
      "          03       0.99      0.99      0.99       282\n",
      "          04       0.97      0.99      0.98       115\n",
      "          05       1.00      0.88      0.94        17\n",
      "          06       1.00      1.00      1.00        25\n",
      "          07       0.97      0.97      0.97       129\n",
      "          08       0.99      0.94      0.96        95\n",
      "          09       0.95      1.00      0.98        59\n",
      "          10       1.00      0.94      0.97        31\n",
      "          11       0.89      1.00      0.94        32\n",
      "          12       0.99      0.97      0.98        69\n",
      "          13       0.89      0.94      0.92        18\n",
      "          14       0.90      1.00      0.95         9\n",
      "          15       0.98      1.00      0.99        94\n",
      "          16       1.00      0.97      0.99        71\n",
      "          17       0.92      0.89      0.91        38\n",
      "          18       0.95      0.97      0.96        38\n",
      "          19       0.89      0.86      0.88        57\n",
      "          20       0.91      0.95      0.93       143\n",
      "          21       0.88      0.84      0.86        77\n",
      "          22       0.94      0.95      0.95       105\n",
      "          23       0.97      0.97      0.97        60\n",
      "          24       1.00      0.97      0.99        35\n",
      "          25       0.99      0.98      0.98        81\n",
      "          26       0.92      0.96      0.94        51\n",
      "          27       0.95      0.96      0.95        72\n",
      "          28       0.95      0.96      0.96       233\n",
      "          29       0.95      0.93      0.94       588\n",
      "          30       0.99      0.82      0.90       101\n",
      "          31       1.00      0.93      0.96        28\n",
      "          32       0.91      0.88      0.89       114\n",
      "          33       0.87      0.93      0.90       148\n",
      "          34       0.98      0.85      0.91        72\n",
      "          35       0.93      0.81      0.87        32\n",
      "          36       1.00      0.87      0.93        15\n",
      "          37       0.97      1.00      0.98        59\n",
      "          38       0.89      0.87      0.88       169\n",
      "          39       0.86      0.78      0.82       508\n",
      "          40       0.87      0.83      0.85       341\n",
      "          41       0.99      1.00      0.99        77\n",
      "          42       0.84      0.84      0.84        51\n",
      "          43       1.00      1.00      1.00        20\n",
      "          44       0.95      0.98      0.96       179\n",
      "          45       1.00      1.00      1.00         8\n",
      "          46       1.00      0.97      0.99        37\n",
      "          47       1.00      1.00      1.00        29\n",
      "          48       0.99      0.96      0.98       200\n",
      "          49       0.90      0.74      0.81        50\n",
      "          50       1.00      1.00      1.00        10\n",
      "          51       0.98      1.00      0.99        57\n",
      "          52       0.98      1.00      0.99       154\n",
      "          53       0.97      1.00      0.98        28\n",
      "          54       0.99      0.99      0.99        92\n",
      "          55       0.99      0.99      0.99       128\n",
      "          56       0.94      0.88      0.91        50\n",
      "          57       0.98      0.96      0.97        47\n",
      "          58       1.00      0.97      0.98        63\n",
      "          59       0.97      0.97      0.97        36\n",
      "          60       1.00      0.93      0.96        55\n",
      "          61       0.99      0.93      0.96       197\n",
      "          62       0.96      0.98      0.97       240\n",
      "          63       0.94      0.96      0.95        80\n",
      "          64       0.99      0.95      0.97        74\n",
      "          65       1.00      0.96      0.98        28\n",
      "          66       1.00      1.00      1.00         8\n",
      "          67       0.89      0.96      0.92        25\n",
      "          68       0.94      0.97      0.95        86\n",
      "          69       0.93      0.95      0.94        65\n",
      "          70       0.87      0.94      0.90       140\n",
      "          71       0.89      0.89      0.89       185\n",
      "          72       0.99      1.00      0.99       242\n",
      "          73       0.86      0.79      0.83       481\n",
      "          74       0.97      0.97      0.97        77\n",
      "          75       1.00      1.00      1.00        24\n",
      "          76       0.99      0.99      0.99      1945\n",
      "          78       1.00      0.93      0.96        14\n",
      "          79       0.89      1.00      0.94        16\n",
      "          80       1.00      0.85      0.92        13\n",
      "          81       0.94      0.98      0.96        61\n",
      "          82       0.82      0.81      0.81       125\n",
      "          83       0.70      0.68      0.69       123\n",
      "          84       0.89      0.86      0.87      1355\n",
      "          85       0.78      0.88      0.83      1170\n",
      "          86       1.00      1.00      1.00        32\n",
      "          87       0.85      0.88      0.87      1329\n",
      "          88       0.60      0.83      0.69        90\n",
      "          89       1.00      0.97      0.98        30\n",
      "          90       0.90      0.80      0.85       314\n",
      "          91       0.97      0.98      0.97        86\n",
      "          92       0.97      0.97      0.97        40\n",
      "          93       1.00      0.96      0.98        23\n",
      "          94       0.92      0.88      0.90       150\n",
      "          95       0.92      0.83      0.88        59\n",
      "          96       0.97      0.90      0.94       114\n",
      "          97       0.83      1.00      0.91        10\n",
      "\n",
      "    accuracy                           0.91     14742\n",
      "   macro avg       0.94      0.94      0.94     14742\n",
      "weighted avg       0.92      0.91      0.91     14742\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print (classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save Model\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['model_chapter.pkl']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#save the model\n",
    "print(\"Save Model\")\n",
    "import joblib\n",
    "joblib.dump(model, 'model_chapter.pkl', compress=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load Model\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "print(\"Load Model\")\n",
    "model = joblib.load('model_chapter.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video game consoles\n"
     ]
    }
   ],
   "source": [
    "products = input()  # Video game consoles : 95"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'95'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict([products])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "248.324px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
