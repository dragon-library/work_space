{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A Production ready Multi-Class Text Classifier\n",
    "==\n",
    "\n",
    "- [Reference :](https://towardsdatascience.com/a-production-ready-multi-class-text-classifier-96490408757)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-30T06:32:18.350303Z",
     "start_time": "2020-11-30T06:32:18.341310Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from time import time\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "import joblib\n",
    "pd.set_option('display.max_rows', 20, \n",
    "              'display.max_columns', 100)\n",
    "\n",
    "#urls = 'https://github.com/dragon-library/work_space/raw/main/HS_Code/HS/hs_code.xlsx'\n",
    "urls = 'data/hs_code.xlsx'\n",
    "types = 'section'\n",
    "#types = \"chapter\"\n",
    "\n",
    "def get_master(sheets,types = 'section'):\n",
    "    data = pd.read_excel(urls,sheet_name= sheets)\n",
    "    data[types] = data[types].map('{:02}'.format)\n",
    "    data = data[[types,'description']]\n",
    "    data['description'] = data['description'].str.lower()\n",
    " #   data = data.rename(columns={'heading' : 'target', 'product_desc' : 'question_text'})\n",
    "     \n",
    "\n",
    "    return data\n",
    "\n",
    "def manage_data(df):\n",
    "    df.columns = ['target', 'data']   \n",
    "    \n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-30T06:22:38.748869Z",
     "start_time": "2020-11-30T06:20:25.759252Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load the dataset: Section\n",
      "Load dataset time:  132.963s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01</td>\n",
       "      <td>horses; live, purebred breeding animals - pure...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01</td>\n",
       "      <td>horses; live, other than purebred breeding ani...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01</td>\n",
       "      <td>asses; live - other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01</td>\n",
       "      <td>mules and hinnies; live-  other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01</td>\n",
       "      <td>cattle; live, purebred breeding animals - pure...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  target                                               data\n",
       "0     01  horses; live, purebred breeding animals - pure...\n",
       "1     01  horses; live, other than purebred breeding ani...\n",
       "2     01                                asses; live - other\n",
       "3     01                    mules and hinnies; live-  other\n",
       "4     01  cattle; live, purebred breeding animals - pure..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "types = \"section\"\n",
    "#types = \"chapter\"\n",
    "\n",
    "print(\"Load the dataset: Section\")\n",
    "t0 = time()\n",
    "\n",
    "sheets = '8_digit'\n",
    "eights = get_master(sheets,types)\n",
    "sheets = '6_digit'\n",
    "sixs = get_master(sheets,types)\n",
    "sheets = '4_digit'\n",
    "fours = get_master(sheets,types)\n",
    "sheets = '2_digit'\n",
    "twos = get_master(sheets,types)\n",
    "\n",
    "sheets = 'test_01'\n",
    "tests = get_master(sheets,types)\n",
    "\n",
    "sheets = 'Declaration_2019_10'\n",
    "decl = get_master(sheets,types)\n",
    "\n",
    "data = pd.concat([eights,sixs,fours,twos,tests,decl], ignore_index=True)\n",
    "twenty_train = manage_data(data)\n",
    "\n",
    "\n",
    "#twenty_test = manage_data(tests)\n",
    "load_time = time() - t0\n",
    "print(\"Load dataset time:  %0.3fs\" % load_time)\n",
    "\n",
    "twenty_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28910"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(twenty_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'01': 1721,\n",
       "         '02': 1471,\n",
       "         '03': 314,\n",
       "         '04': 1632,\n",
       "         '05': 639,\n",
       "         '06': 4113,\n",
       "         '07': 1227,\n",
       "         '08': 414,\n",
       "         '09': 720,\n",
       "         '10': 759,\n",
       "         '11': 3838,\n",
       "         '12': 360,\n",
       "         '13': 785,\n",
       "         '14': 285,\n",
       "         '15': 2802,\n",
       "         '16': 4524,\n",
       "         '17': 1279,\n",
       "         '18': 1145,\n",
       "         '19': 89,\n",
       "         '20': 763,\n",
       "         '21': 29,\n",
       "         '00': 1})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "Counter(twenty_train[\"target\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re \n",
    "def clean_str(string):\n",
    "    \"\"\"\n",
    "    Tokenization/string cleaning for dataset\n",
    "    Every dataset is lower cased except\n",
    "    \"\"\"\n",
    "    string = re.sub(r\"\\n\", \"\", string)    \n",
    "    string = re.sub(r\"\\r\", \"\", string) \n",
    "    string = re.sub(r\"[0-9]\", \"digit\", string)\n",
    "    string = re.sub(r\"\\'\", \"\", string)    \n",
    "    string = re.sub(r\"\\\"\", \"\", string)    \n",
    "    return string.strip().lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train test split dataset\n"
     ]
    }
   ],
   "source": [
    "print(\"train test split dataset\")\n",
    "#train test split\n",
    "df = twenty_train.copy()\n",
    "from sklearn.model_selection import train_test_split\n",
    "X = []\n",
    "for i in range(df.shape[0]):\n",
    "    X.append(clean_str(df.iloc[i][1]))\n",
    "y = np.array(df[\"target\"])\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: \n"
     ]
    }
   ],
   "source": [
    "#feature engineering and model selection\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "print(\"Training: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pipeline of feature engineering and model\n",
    "t0 = time()\n",
    "model = Pipeline([('vectorizer', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', OneVsRestClassifier(LinearSVC(class_weight=\"balanced\")))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "paramater selection\n"
     ]
    }
   ],
   "source": [
    "print(\"paramater selection\")\n",
    "#paramater selection\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "parameters = {'vectorizer__ngram_range': [(1, 1), (1, 2),(2,2)],\n",
    "               'tfidf__use_idf': (True, False)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:670: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.961604980975441\n",
      "{'tfidf__use_idf': True, 'vectorizer__ngram_range': (1, 2)}\n"
     ]
    }
   ],
   "source": [
    "gs_clf_svm = GridSearchCV(model, parameters, n_jobs=-1)\n",
    "gs_clf_svm = gs_clf_svm.fit(X, y)\n",
    "print(gs_clf_svm.best_score_)\n",
    "print(gs_clf_svm.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preparing the final pipeline using the selected parameters\n"
     ]
    }
   ],
   "source": [
    "#preparing the final pipeline using the selected parameters\n",
    "print(\"preparing the final pipeline using the selected parameters\")\n",
    "model = Pipeline([('vectorizer', CountVectorizer(ngram_range=(1,2))),\n",
    "    ('tfidf', TfidfTransformer(use_idf=True)),\n",
    "    ('clf', OneVsRestClassifier(LinearSVC(class_weight=\"balanced\")))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model with training data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train time: 208.141s\n"
     ]
    }
   ],
   "source": [
    "#fit model with training data\n",
    "print(\"fit model with training data\")\n",
    "model.fit(X_train, y_train)\n",
    "train_time = time() - t0\n",
    "print(\"train time: %0.3fs\" % train_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test time:  0.467s\n"
     ]
    }
   ],
   "source": [
    "#evaluation on test data\n",
    "t0 = time()\n",
    "pred = model.predict(X_test)\n",
    "test_time = time() - t0\n",
    "print(\"test time:  %0.3fs\" % test_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['01', '02', '03', '04', '05', '06', '07', '08', '09', '10', '11',\n",
       "       '12', '13', '14', '15', '16', '17', '18', '19', '20', '21'],\n",
       "      dtype='<U2')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
       "       [   0,  521,    1,    0,    1,    0,    3,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
       "       [   0,    0,  417,    0,    1,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    1,    0,    0,    0,    0,    0],\n",
       "       [   0,    0,    0,   85,    0,    0,    1,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
       "       [   0,    1,    0,    0,  464,    0,    3,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
       "       [   0,    0,    0,    0,    0,  191,    6,    0,    0,    0,    0,\n",
       "           0,    0,    1,    0,    0,    0,    0,    0,    0,    0,    0],\n",
       "       [   1,    1,    3,    1,    3,    1, 1253,    5,    0,    0,    1,\n",
       "           0,    0,    0,    0,    3,    1,    0,    2,    0,    2,    0],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,  343,    0,    0,    0,\n",
       "           0,    0,    1,    0,    0,    0,    0,    0,    0,    1,    0],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,  122,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
       "       [   0,    0,    0,    0,    0,    0,    3,    0,    0,  221,    0,\n",
       "           0,    0,    0,    0,    0,    1,    0,    0,    0,    0,    0],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,  216,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "        1140,    0,    3,    0,    0,    0,    0,    0,    0,    5,    0],\n",
       "       [   0,    1,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,  113,    0,    0,    0,    0,    0,    0,    0,    1,    0],\n",
       "       [   0,    0,    0,    0,    0,    1,    1,    0,    0,    0,    0,\n",
       "           0,    0,  235,    1,    0,    0,    0,    0,    0,    0,    0],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,   77,    0,    0,    0,    0,    0,    0,    0],\n",
       "       [   0,    0,    0,    0,    0,    1,    4,    1,    0,    0,    0,\n",
       "           0,    1,    0,    0,  857,    0,    0,    0,    0,    1,    0],\n",
       "       [   0,    0,    0,    0,    0,    0,    3,    1,    0,    0,    0,\n",
       "           0,    0,    0,    0,    2, 1342,    1,    7,    0,    2,    0],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    2,  377,    0,    0,    0,    0],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    1,    0,\n",
       "           0,    0,    0,    0,    0,    4,    0,  350,    0,    1,    0],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,   24,    0,    0],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    1,    0,    0,    0,    0,    0,    0,  224,    0],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    6]],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "confusion_matrix(pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9890464660440448"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          00       0.00      0.00      0.00         1\n",
      "          01       0.99      0.99      0.99       524\n",
      "          02       1.00      0.99      0.99       421\n",
      "          03       0.99      0.99      0.99        86\n",
      "          04       0.99      0.99      0.99       469\n",
      "          05       0.96      0.98      0.97       194\n",
      "          06       0.98      0.98      0.98      1277\n",
      "          07       0.99      0.98      0.99       350\n",
      "          08       1.00      1.00      1.00       122\n",
      "          09       0.98      1.00      0.99       222\n",
      "          10       1.00      1.00      1.00       217\n",
      "          11       0.99      1.00      1.00      1140\n",
      "          12       0.98      0.99      0.99       114\n",
      "          13       0.99      0.98      0.98       241\n",
      "          14       1.00      0.99      0.99        78\n",
      "          15       0.99      0.99      0.99       862\n",
      "          16       0.99      0.99      0.99      1351\n",
      "          17       0.99      1.00      1.00       378\n",
      "          18       0.98      0.97      0.98       359\n",
      "          19       1.00      1.00      1.00        24\n",
      "          20       1.00      0.95      0.97       237\n",
      "          21       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           0.99      8673\n",
      "   macro avg       0.95      0.94      0.94      8673\n",
      "weighted avg       0.99      0.99      0.99      8673\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print (classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save Model\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['model_section.pkl']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#save the model\n",
    "print(\"Save Model\")\n",
    "import joblib\n",
    "joblib.dump(model, 'model_section.pkl', compress=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-30T06:32:23.015089Z",
     "start_time": "2020-11-30T06:32:22.998100Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load Model\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/train/df_master_train.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-24ec2c8a20d3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mjoblib\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Load Model\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mjoblib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'data/train/df_master_train.pkl'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"download data...\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtypes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'description'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\numpy_pickle.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(filename, mmap_mode)\u001b[0m\n\u001b[0;32m    575\u001b[0m             \u001b[0mobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_unpickle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    576\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 577\u001b[1;33m         \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    578\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0m_read_fileobject\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmmap_mode\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mfobj\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    579\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/train/df_master_train.pkl'"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "print(\"Load Model\")\n",
    "df = joblib.load('data/train/df_master_train.pkl')\n",
    "print(\"download data...\") \n",
    "df = df[[types, 'description']]   \n",
    "df.columns = ['target', 'data']\n",
    "n = df.isnull().sum()\n",
    "print(\"missing values : \", n )\n",
    "df.dropna(inplace=True)\n",
    "df['target'] = df['target'].apply(int)\n",
    "print(\"Load Data.. \"+types+\" success\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video game consoles\n"
     ]
    }
   ],
   "source": [
    "products = input()  # Video game consoles : 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'20'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict([products])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chapter Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load the dataset : chapter\n",
      "Load dataset time:  85.046s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01</td>\n",
       "      <td>horses; live, purebred breeding animals - pure...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01</td>\n",
       "      <td>horses; live, other than purebred breeding ani...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01</td>\n",
       "      <td>asses; live - other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01</td>\n",
       "      <td>mules and hinnies; live-  other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01</td>\n",
       "      <td>cattle; live, purebred breeding animals - pure...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  target                                               data\n",
       "0     01  horses; live, purebred breeding animals - pure...\n",
       "1     01  horses; live, other than purebred breeding ani...\n",
       "2     01                                asses; live - other\n",
       "3     01                    mules and hinnies; live-  other\n",
       "4     01  cattle; live, purebred breeding animals - pure..."
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#types = \"section\"\n",
    "types = \"chapter\"\n",
    "\n",
    "print(\"Load the dataset : chapter\")\n",
    "t0 = time()\n",
    "sheets = '8_digit'\n",
    "eights = get_master(sheets,types)\n",
    "sheets = '6_digit'\n",
    "sixs = get_master(sheets,types)\n",
    "sheets = '4_digit'\n",
    "fours = get_master(sheets,types)\n",
    "sheets = '2_digit'\n",
    "twos = get_master(sheets,types)\n",
    "\n",
    "sheets = 'test_01'\n",
    "tests = get_master(sheets,types)\n",
    "\n",
    "data = pd.concat([eights,sixs,fours,twos,tests], ignore_index=True)\n",
    "twenty_train = manage_data(data)\n",
    "\n",
    "\n",
    "#twenty_test = manage_data(tests)\n",
    "\n",
    "load_time = time() - t0\n",
    "print(\"Load dataset time:  %0.3fs\" % load_time)\n",
    "\n",
    "twenty_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28910"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(twenty_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'01': 126,\n",
       "         '02': 253,\n",
       "         '03': 907,\n",
       "         '04': 365,\n",
       "         '05': 70,\n",
       "         '06': 89,\n",
       "         '07': 391,\n",
       "         '08': 310,\n",
       "         '09': 172,\n",
       "         '10': 100,\n",
       "         '11': 115,\n",
       "         '12': 212,\n",
       "         '13': 49,\n",
       "         '14': 33,\n",
       "         '15': 314,\n",
       "         '16': 259,\n",
       "         '17': 129,\n",
       "         '18': 117,\n",
       "         '19': 170,\n",
       "         '20': 372,\n",
       "         '21': 194,\n",
       "         '22': 180,\n",
       "         '23': 108,\n",
       "         '24': 103,\n",
       "         '25': 265,\n",
       "         '26': 148,\n",
       "         '27': 226,\n",
       "         '28': 715,\n",
       "         '29': 1906,\n",
       "         '30': 214,\n",
       "         '31': 85,\n",
       "         '32': 250,\n",
       "         '33': 127,\n",
       "         '34': 131,\n",
       "         '35': 68,\n",
       "         '36': 48,\n",
       "         '37': 127,\n",
       "         '38': 442,\n",
       "         '39': 771,\n",
       "         '40': 456,\n",
       "         '41': 209,\n",
       "         '42': 151,\n",
       "         '43': 54,\n",
       "         '44': 582,\n",
       "         '45': 38,\n",
       "         '46': 100,\n",
       "         '47': 71,\n",
       "         '48': 595,\n",
       "         '49': 93,\n",
       "         '50': 45,\n",
       "         '51': 192,\n",
       "         '52': 513,\n",
       "         '53': 96,\n",
       "         '54': 302,\n",
       "         '55': 374,\n",
       "         '56': 138,\n",
       "         '57': 143,\n",
       "         '58': 206,\n",
       "         '59': 139,\n",
       "         '60': 175,\n",
       "         '61': 510,\n",
       "         '62': 750,\n",
       "         '63': 255,\n",
       "         '64': 233,\n",
       "         '65': 61,\n",
       "         '66': 25,\n",
       "         '67': 41,\n",
       "         '68': 213,\n",
       "         '69': 207,\n",
       "         '70': 365,\n",
       "         '71': 285,\n",
       "         '72': 826,\n",
       "         '73': 686,\n",
       "         '74': 238,\n",
       "         '75': 73,\n",
       "         '76': 199,\n",
       "         '78': 37,\n",
       "         '79': 47,\n",
       "         '80': 32,\n",
       "         '81': 178,\n",
       "         '82': 299,\n",
       "         '83': 187,\n",
       "         '84': 2765,\n",
       "         '85': 1759,\n",
       "         '86': 92,\n",
       "         '87': 1024,\n",
       "         '88': 59,\n",
       "         '89': 104,\n",
       "         '90': 747,\n",
       "         '91': 291,\n",
       "         '92': 107,\n",
       "         '93': 89,\n",
       "         '94': 244,\n",
       "         '95': 198,\n",
       "         '96': 321,\n",
       "         '97': 29,\n",
       "         '99': 1})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "Counter(twenty_train[\"target\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re \n",
    "def clean_str(string):\n",
    "    \"\"\"\n",
    "    Tokenization/string cleaning for dataset\n",
    "    Every dataset is lower cased except\n",
    "    \"\"\"\n",
    "    string = re.sub(r\"\\n\", \"\", string)    \n",
    "    string = re.sub(r\"\\r\", \"\", string) \n",
    "    string = re.sub(r\"[0-9]\", \"digit\", string)\n",
    "    string = re.sub(r\"\\'\", \"\", string)    \n",
    "    string = re.sub(r\"\\\"\", \"\", string)    \n",
    "    return string.strip().lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rain test split\n"
     ]
    }
   ],
   "source": [
    "#train test split\n",
    "print(\"rain test split\")\n",
    "df = twenty_train.copy()\n",
    "from sklearn.model_selection import train_test_split\n",
    "X = []\n",
    "for i in range(df.shape[0]):\n",
    "    X.append(clean_str(df.iloc[i][1]))\n",
    "y = np.array(df[\"target\"])\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature engineering and model selection\n"
     ]
    }
   ],
   "source": [
    "#feature engineering and model selection\n",
    "print(\"feature engineering and model selection\")\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pipeline of feature engineering and model\n"
     ]
    }
   ],
   "source": [
    "#pipeline of feature engineering and model\n",
    "print(\"pipeline of feature engineering and model\")\n",
    "model = Pipeline([('vectorizer', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', OneVsRestClassifier(LinearSVC(class_weight=\"balanced\")))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "paramater selection\n"
     ]
    }
   ],
   "source": [
    "#paramater selection\n",
    "print(\"paramater selection\")\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "parameters = {'vectorizer__ngram_range': [(1, 1), (1, 2),(2,2)],\n",
    "               'tfidf__use_idf': (True, False)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:670: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9574195780006919\n",
      "{'tfidf__use_idf': True, 'vectorizer__ngram_range': (1, 2)}\n"
     ]
    }
   ],
   "source": [
    "print(\"Training: \")\n",
    "   \n",
    "t0 = time()\n",
    "gs_clf_svm = GridSearchCV(model, parameters, n_jobs=-1)\n",
    "gs_clf_svm = gs_clf_svm.fit(X, y)\n",
    "print(gs_clf_svm.best_score_)\n",
    "print(gs_clf_svm.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preparing the final pipeline using the selected parameters\n",
    "model = Pipeline([('vectorizer', CountVectorizer(ngram_range=(1,2))),\n",
    "    ('tfidf', TfidfTransformer(use_idf=True)),\n",
    "    ('clf', OneVsRestClassifier(LinearSVC(class_weight=\"balanced\")))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train time: 976.911s\n"
     ]
    }
   ],
   "source": [
    "#fit model with training data\n",
    "model.fit(X_train, y_train)\n",
    "train_time = time() - t0\n",
    "print(\"train time: %0.3fs\" % train_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test time:  0.513s\n"
     ]
    }
   ],
   "source": [
    "#evaluation on test data\n",
    "t0 = time()\n",
    "pred = model.predict(X_test)\n",
    "\n",
    "test_time = time() - t0\n",
    "print(\"test time:  %0.3fs\" % test_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['01', '02', '03', '04', '05', '06', '07', '08', '09', '10', '11',\n",
       "       '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22',\n",
       "       '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33',\n",
       "       '34', '35', '36', '37', '38', '39', '40', '41', '42', '43', '44',\n",
       "       '45', '46', '47', '48', '49', '50', '51', '52', '53', '54', '55',\n",
       "       '56', '57', '58', '59', '60', '61', '62', '63', '64', '65', '66',\n",
       "       '67', '68', '69', '70', '71', '72', '73', '74', '75', '76', '78',\n",
       "       '79', '80', '81', '82', '83', '84', '85', '86', '87', '88', '89',\n",
       "       '90', '91', '92', '93', '94', '95', '96', '97'], dtype='<U2')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 38,   0,   1, ...,   0,   0,   0],\n",
       "       [  0,  81,   0, ...,   0,   0,   0],\n",
       "       [  0,   0, 277, ...,   0,   0,   0],\n",
       "       ...,\n",
       "       [  0,   0,   0, ..., 101,   0,   0],\n",
       "       [  0,   0,   0, ...,   0,   6,   0],\n",
       "       [  0,   0,   0, ...,   0,   0,   0]], dtype=int64)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "confusion_matrix(pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9823590453130405\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_test, pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          01       0.95      1.00      0.97        38\n",
      "          02       1.00      1.00      1.00        81\n",
      "          03       1.00      0.99      1.00       279\n",
      "          04       0.96      1.00      0.98       107\n",
      "          05       0.94      0.89      0.92        19\n",
      "          06       1.00      0.96      0.98        25\n",
      "          07       0.98      0.98      0.98       126\n",
      "          08       0.96      0.96      0.96        81\n",
      "          09       0.92      0.94      0.93        51\n",
      "          10       1.00      1.00      1.00        23\n",
      "          11       0.97      0.97      0.97        36\n",
      "          12       1.00      1.00      1.00        59\n",
      "          13       1.00      1.00      1.00        13\n",
      "          14       1.00      1.00      1.00         7\n",
      "          15       0.99      0.98      0.98        86\n",
      "          16       0.99      1.00      0.99        72\n",
      "          17       1.00      1.00      1.00        36\n",
      "          18       1.00      1.00      1.00        29\n",
      "          19       1.00      0.96      0.98        46\n",
      "          20       1.00      0.98      0.99       118\n",
      "          21       0.95      0.98      0.96        55\n",
      "          22       1.00      0.96      0.98        46\n",
      "          23       0.97      1.00      0.98        32\n",
      "          24       1.00      1.00      1.00        35\n",
      "          25       0.92      0.97      0.94        79\n",
      "          26       1.00      0.98      0.99        48\n",
      "          27       1.00      1.00      1.00        67\n",
      "          28       0.95      0.94      0.95       222\n",
      "          29       0.95      0.97      0.96       594\n",
      "          30       0.99      0.99      0.99        68\n",
      "          31       1.00      0.97      0.98        29\n",
      "          32       1.00      0.92      0.96        75\n",
      "          33       1.00      0.88      0.94        41\n",
      "          34       1.00      0.90      0.95        42\n",
      "          35       1.00      0.83      0.90        23\n",
      "          36       1.00      0.93      0.97        15\n",
      "          37       0.98      1.00      0.99        43\n",
      "          38       0.96      0.93      0.94       125\n",
      "          39       0.99      0.96      0.97       222\n",
      "          40       0.99      1.00      1.00       128\n",
      "          41       1.00      1.00      1.00        60\n",
      "          42       1.00      1.00      1.00        46\n",
      "          43       1.00      1.00      1.00        16\n",
      "          44       0.98      0.99      0.99       190\n",
      "          45       1.00      1.00      1.00        10\n",
      "          46       1.00      1.00      1.00        22\n",
      "          47       1.00      1.00      1.00        18\n",
      "          48       1.00      0.99      1.00       176\n",
      "          49       1.00      1.00      1.00        23\n",
      "          50       1.00      1.00      1.00        11\n",
      "          51       0.98      1.00      0.99        57\n",
      "          52       0.99      1.00      0.99       148\n",
      "          53       1.00      1.00      1.00        33\n",
      "          54       1.00      1.00      1.00       103\n",
      "          55       1.00      1.00      1.00       119\n",
      "          56       0.89      1.00      0.94        33\n",
      "          57       1.00      1.00      1.00        37\n",
      "          58       1.00      1.00      1.00        50\n",
      "          59       1.00      1.00      1.00        38\n",
      "          60       0.98      1.00      0.99        48\n",
      "          61       0.99      0.99      0.99       158\n",
      "          62       0.99      1.00      0.99       220\n",
      "          63       0.99      0.98      0.98        85\n",
      "          64       1.00      1.00      1.00        74\n",
      "          65       1.00      1.00      1.00        23\n",
      "          66       0.83      0.83      0.83         6\n",
      "          67       0.92      1.00      0.96        11\n",
      "          68       0.97      0.98      0.98        66\n",
      "          69       1.00      1.00      1.00        45\n",
      "          70       0.99      0.98      0.99       130\n",
      "          71       0.99      0.99      0.99        78\n",
      "          72       0.98      0.99      0.99       254\n",
      "          73       0.99      0.99      0.99       203\n",
      "          74       0.97      0.99      0.98        71\n",
      "          75       1.00      1.00      1.00        26\n",
      "          76       0.97      1.00      0.98        64\n",
      "          78       0.93      0.81      0.87        16\n",
      "          79       0.86      1.00      0.92        12\n",
      "          80       0.92      1.00      0.96        11\n",
      "          81       0.94      1.00      0.97        50\n",
      "          82       0.98      0.99      0.99       102\n",
      "          83       1.00      0.98      0.99        53\n",
      "          84       0.99      0.99      0.99       802\n",
      "          85       0.99      0.99      0.99       549\n",
      "          86       0.96      1.00      0.98        22\n",
      "          87       0.99      1.00      1.00       313\n",
      "          88       1.00      1.00      1.00        15\n",
      "          89       1.00      0.96      0.98        28\n",
      "          90       0.98      0.96      0.97       227\n",
      "          91       0.99      0.99      0.99        94\n",
      "          92       1.00      1.00      1.00        38\n",
      "          93       1.00      1.00      1.00        24\n",
      "          94       1.00      0.97      0.99        69\n",
      "          95       1.00      0.94      0.97        63\n",
      "          96       0.98      0.96      0.97       105\n",
      "          97       1.00      1.00      1.00         6\n",
      "          99       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.98      8673\n",
      "   macro avg       0.97      0.97      0.97      8673\n",
      "weighted avg       0.98      0.98      0.98      8673\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print (classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save Model\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['model_chapter.pkl']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#save the model\n",
    "print(\"Save Model\")\n",
    "import joblib\n",
    "joblib.dump(model, 'model_chapter.pkl', compress=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load Model\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "print(\"Load Model\")\n",
    "model = joblib.load('model_chapter.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video game consoles\n"
     ]
    }
   ],
   "source": [
    "products = input()  # Video game consoles : 95"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'95'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict([products])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "248.352px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
